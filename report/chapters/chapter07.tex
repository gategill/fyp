This section covers the experimental side if the project. We introduce several metrics to compare the performance of the models
\section{Setup}

\section{Evaluation Metrics}

\subsection{Mean Absolute Error (MAE)}
MAE is one of the simplest metrics used to evaluate recommender systems. It is what is says it is: an average of the errors between our predicted rating and the true rating. 


Also, it is limited in the insight it can provide us compared to more modern metrics

\subsection{Normalized Discounted Cumulative Gain}

\subsection{Precision}

\subsection{Item Coverage}

\subsection{GINI}

\subsection{EPC???}

\section{Experimental Results}

\section{Discussion}